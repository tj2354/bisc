{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93b2658f-ba8f-41be-b512-7d0049363bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/anup.das/.conda/envs/py3_env/lib/python3.7/site-packages/ptsa/data/readers/index.py:39: FutureWarning: Lab-specific readers may be moved to the cmlreaders package (https://github.com/pennmem/cmlreaders)\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import typing\n",
    "from utils import (get_session, get_stim, get_fs, get_raw_responses)\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats, signal\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import resample\n",
    "from numpy.lib.recfunctions import append_fields, merge_arrays\n",
    "from nilearn import plotting\n",
    "from scipy.stats import circmean\n",
    "import pycircstat\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import dask\n",
    "\n",
    "import sys\n",
    "from SubjectLevel.par_funcs import *\n",
    "import par_funcs\n",
    "sys.path.append('/home1/anup.das')\n",
    "import pickle\n",
    "import glob\n",
    "import mat73\n",
    "\n",
    "from tarjan import tarjan\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "import matplotlib.colors as clrs\n",
    "import matplotlib.cm as cmx\n",
    "import nilearn.plotting as ni_plot\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pylab as pyl\n",
    "from PIL import Image\n",
    "import os\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from SubjectLevel.par_funcs_fine import *\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from ptsa.data.readers import EEGReader\n",
    "from ptsa.data.filters import ResampleFilter\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "from ptsa.data.filters import ButterworthFilter\n",
    "from ptsa.data.filters import MorletWaveletFilter\n",
    "from ptsa.data.filters import ResampleFilter\n",
    "from ptsa.data.timeseries import TimeSeries\n",
    "\n",
    "import mne\n",
    "from mne.viz import plot_alignment, snapshot_brain_montage\n",
    "from mne import create_info, EpochsArray\n",
    "from mne.baseline import rescale\n",
    "from mne.time_frequency import (tfr_multitaper, tfr_stockwell, tfr_morlet,\n",
    "                                tfr_array_morlet)\n",
    "from mne.viz import centers_to_edges\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import cluster_helper.cluster\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from types import SimpleNamespace\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509f5675-766d-4456-8033-a506ca3c237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial onsets in ms: (401,)\n",
      "trial offsets in ms: (401,)\n",
      "401 trials in the session, average duration 2002.1 ms\n",
      "40 dots presented in each trial\n"
     ]
    }
   ],
   "source": [
    "session_id = '39491886'\n",
    "session = get_session(session_id)\n",
    "session\n",
    "\n",
    "onsets, offsets, stim_params = get_stim(session)\n",
    "\n",
    "num_trials, num_dots, _ = stim_params['dot_locations'].shape\n",
    "print('trial onsets in ms: {}'.format(onsets.shape))\n",
    "print('trial offsets in ms: {}'.format(offsets.shape))\n",
    "print('{} trials in the session, average duration {:.1f} ms'.format(num_trials, np.mean(offsets-onsets)))\n",
    "print('{} dots presented in each trial'.format(num_dots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caeb462a-3646-4595-a809-e2cefb54a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create coordinates of channels\n",
    "xg = np.empty((32, 32))\n",
    "yg = np.empty((32, 32))\n",
    "\n",
    "hor_pitch = 26.5\n",
    "ver_pitch = 29\n",
    "\n",
    "for i_coord in range(0, 32, 1):\n",
    "    for j_coord in range(0, 32, 1):\n",
    "        \n",
    "        xg[i_coord, j_coord] = -i_coord*ver_pitch\n",
    "        yg[i_coord, j_coord] = j_coord*hor_pitch\n",
    "\n",
    "xg_reshaped = np.reshape(xg, (1024, 1))\n",
    "yg_reshaped = np.reshape(yg, (1024, 1))\n",
    "coords = np.array(np.hstack((xg_reshaped, yg_reshaped)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1c76d0-cb06-4b43-98d8-05a7fb1fd6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = get_fs(session)\n",
    "\n",
    "diffvals = []\n",
    "for i_trial in range(0, len(offsets), 1):\n",
    "    diffvals.append(offsets[i_trial] - onsets[i_trial])\n",
    "\n",
    "eeg_all_chans = []\n",
    "\n",
    "for i_trial in range(0, len(onsets), 1):\n",
    "    tic, toc = onsets[i_trial]-1000, onsets[i_trial] + np.ceil(np.max(diffvals)) +1000 # a time interval covering the first trial\n",
    "    if (toc-tic > 4082.5):\n",
    "        toc -= 1\n",
    "    responses = get_raw_responses(session, tic, toc)\n",
    "    \n",
    "    time_axis_length = np.squeeze(responses[0, :].shape)\n",
    "    new_length = int(np.round(time_axis_length * 500 / float(fs)))\n",
    "    responses_resampled = resample(responses.T, new_length).T\n",
    "    eeg_all_chans.append(responses_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30d90122-e206-4b4a-a828-7e5ed35b1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create spatial channels\n",
    "channel_idxs = np.arange(1024)\n",
    "\n",
    "eeg_all_chans = np.array(eeg_all_chans)\n",
    "\n",
    "sweep_offsets = [(0, 0), (1, 0), (1, 1), (0, 1)]\n",
    "idx_map = np.empty((32, 32), dtype=int)\n",
    "for i, (y, x) in enumerate(sweep_offsets):\n",
    "    idx_map[y::2, x::2] = channel_idxs[i*256:(i+1)*256].reshape(16, 16)\n",
    "\n",
    "idx_map_reshaped = idx_map.reshape(np.shape(eeg_all_chans)[1],1)\n",
    "eeg_all_chans_spatial = []\n",
    "for i_trial in range(0, np.shape(eeg_all_chans)[0], 1):\n",
    "    data_mat_tmp = np.empty((np.shape(eeg_all_chans)[1], np.shape(eeg_all_chans)[2]))\n",
    "    data_mat_orig = eeg_all_chans[i_trial, :, :]\n",
    "    for i_elec in range(0, np.shape(eeg_all_chans)[1], 1):\n",
    "        data_mat_tmp[i_elec, :] = data_mat_orig[idx_map_reshaped[i_elec], :]\n",
    "    eeg_all_chans_spatial.append(data_mat_tmp)\n",
    "eeg_all_chans_spatial = np.array(eeg_all_chans_spatial)\n",
    "with open('/home1/anup.das/dense-session-share_081224/Results/resampled_eeg_spatial_39491886.pkl', 'wb') as f:\n",
    "        pickle.dump(eeg_all_chans_spatial, f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2924a3d-dcb6-4b17-8fc3-8d2555a09bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home1/anup.das/dense-session-share_081224/Results/resampled_eeg_spatial_39491886.pkl', 'rb') as f:\n",
    "    eeg_all_chans_spatial = np.array(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "470d1e69-f03d-47a6-ba21-5aebc10984d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique port for anup.das is 51437\n",
      "{'dashboard_address': ':51437'}\n",
      "To view the dashboard, run: \n",
      "`ssh -fN anup.das@rhino2.psych.upenn.edu -L 8000:192.168.86.144:51437` in your local computer's terminal (NOT rhino) \n",
      "and then navigate to localhost:8000 in your browser\n"
     ]
    }
   ],
   "source": [
    "#implement RAM dask based traveling waves analysis\n",
    "import cmldask\n",
    "from dask.distributed import wait, progress\n",
    "from cmldask import CMLDask as da\n",
    "\n",
    "client = da.new_dask_client_slurm('traveling_waves', '8GB', max_n_jobs = 50, walltime = '100000', log_directory = '/home1/anup.das/logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "916beb84-ac79-4964-9715-da0ae5c4d759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band pass EEG\n",
      "Traveling wave analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1008/1008 [1:46:22<00:00,  6.33s/it] \n"
     ]
    }
   ],
   "source": [
    "#implement RAM dask based traveling waves analysis\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "session_id = '39491886'\n",
    "session = get_session(session_id)\n",
    "\n",
    "fs = get_fs(session)\n",
    "\n",
    "onsets, offsets, stim_params = get_stim(session)\n",
    "\n",
    "num_trials, num_dots, _ = stim_params['dot_locations'].shape\n",
    "\n",
    "dot_locations = stim_params['dot_locations']\n",
    "dot_colors = stim_params['dot_colors']\n",
    "fs = get_fs(session)\n",
    "\n",
    "locations_all = np.reshape(stim_params['dot_locations'], (401*40, 2))\n",
    "locations_unique = np.unique(locations_all, axis=0)\n",
    "\n",
    "DOT_TIME = 50\n",
    "TIME_PAST_STIM = [40,90]\n",
    "TRIAL_TIME_PAD = [0.1,0.1+TIME_PAST_STIM[1]-DOT_TIME]\n",
    "\n",
    "dot_starts = []\n",
    "dot_ends = []\n",
    "\n",
    "for trial in range(dot_locations.shape[0]):\n",
    "\n",
    "    dot_st_frame = []\n",
    "    dot_end_frame = []\n",
    "    \n",
    "    # for each dot\n",
    "    for d in range(dot_locations.shape[1]):\n",
    "\n",
    "        # get start and end frame\n",
    "        st_temp = np.int16(np.ceil((d*DOT_TIME + TRIAL_TIME_PAD[0] + TIME_PAST_STIM[0]) * (fs/1000)))\n",
    "        end_tmp = np.int16(st_temp + np.ceil(TIME_PAST_STIM[1] * (fs/1000)))\n",
    "        \n",
    "        dot_st_frame.append(st_temp)\n",
    "        dot_end_frame.append(end_tmp)\n",
    "        \n",
    "    dot_starts.append(dot_st_frame)\n",
    "    dot_ends.append(dot_end_frame)\n",
    "    \n",
    "dot_starts = np.array(dot_starts).astype(float)\n",
    "dot_ends = np.array(dot_ends).astype(float)\n",
    "\n",
    "\n",
    "channel_idxs = np.arange(1024)\n",
    "\n",
    "sweep_offsets = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "idx_map = np.empty((32, 32), dtype=int)\n",
    "for i, (y, x) in enumerate(sweep_offsets):\n",
    "    idx_map[y::2, x::2] = channel_idxs[i*256:(i+1)*256].reshape(16, 16)\n",
    "\n",
    "idx_map_reshaped = idx_map.reshape(len(channel_idxs),1)\n",
    "\n",
    "\n",
    "#filter signals and calculate power\n",
    "def butter_bandpass(lowcut, highcut, fs, order=3):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#run traveling waves analysis\n",
    "#reshape the data matrix into channel by trial by frame dimensional matrix\n",
    "eeg = eeg_all_chans_spatial.transpose(1, 0, 2)\n",
    "\n",
    "res_global = {}\n",
    "task_phase = 'STIMULI'\n",
    "\n",
    "print('Band pass EEG')\n",
    "time_frame_start=500\n",
    "time_frame_end=np.shape(eeg_all_chans_spatial)[2] - 500\n",
    "thetas = np.radians(np.arange(0, 360, 5))\n",
    "rs = np.radians(np.arange(0, 180/29, 0.5))\n",
    "theta_r = np.stack([(x, y) for x in thetas for y in rs])\n",
    "params = np.stack([theta_r[:, 1] * np.cos(theta_r[:, 0]), theta_r[:, 1] * np.sin(theta_r[:, 0])], -1)\n",
    "f=par_funcs.circ_lin_regress\n",
    "\n",
    "#allowed electrodes\n",
    "allowed_elecs = np.ones((len(coords)), dtype=bool)\n",
    "saturating_ch_inds = np.hstack([range(0,8), range(1016,1024)])\n",
    "n_allowed_elecs_inds = np.where(idx_map_reshaped == saturating_ch_inds)[0]\n",
    "allowed_elecs[n_allowed_elecs_inds] = False\n",
    "\n",
    "i=1\n",
    "print('Traveling wave analysis')\n",
    "#while 'cluster{}'.format(i) in self.res['clusters'].columns:\n",
    "while 'cluster{}'.format(i) in 'cluster1':\n",
    "    res={}\n",
    "    clusterphase=[]\n",
    "    clusterpower=[]\n",
    "    clustereeg=[]\n",
    "    cluster='cluster{}'.format(i)\n",
    "    for j in range(len(allowed_elecs)):\n",
    "        if allowed_elecs[j]:\n",
    "            feeg=butter_bandpass_filter(eeg[j], 30 *.85, 90/.85, 500, order=3)\n",
    "            clusterphase.append(np.angle(hilbert(feeg, N=feeg.shape[-1], axis=-1)))\n",
    "            clusterpower.append(np.abs(hilbert(feeg, N=feeg.shape[-1], axis=-1)))\n",
    "            clustereeg.append(feeg)\n",
    "    res['power']=np.stack(clusterpower)[:,:,time_frame_start:time_frame_end].astype('float32') \n",
    "    res['phase']=np.stack(clusterphase)[:,:,time_frame_start:time_frame_end].astype('float32') \n",
    "    res['eeg']=np.stack(clustereeg)[:,:,time_frame_start:time_frame_end].astype('float32') \n",
    "    \n",
    "    xyz = coords\n",
    "    xyz = xyz[allowed_elecs]\n",
    "    elec_dists = squareform(pdist(xyz))\n",
    "    near_adj_matr = (elec_dists < 80)\n",
    "\n",
    "    local_angle={}\n",
    "    local_sf={}\n",
    "    local_rs={}\n",
    "    local_off={}\n",
    "    for j in tqdm(range(0,len(xyz))):\n",
    "        if sum(near_adj_matr[j])>3:\n",
    "            norm_coords = xyz[near_adj_matr[j],:]\n",
    "\n",
    "            num_iters = int(res['phase'][near_adj_matr[j]].T.shape[0])\n",
    "            \n",
    "            data_as_list = zip(res['phase'][near_adj_matr[j]].T,np.array([norm_coords]*num_iters), [theta_r]*num_iters, [params]*num_iters)\n",
    "            arg1 = [(x[0]) for x in data_as_list]\n",
    "\n",
    "            data_as_list = zip(res['phase'][near_adj_matr[j]].T,np.array([norm_coords]*num_iters), [theta_r]*num_iters, [params]*num_iters)\n",
    "            arg2 = [(x[1]) for x in data_as_list]\n",
    "\n",
    "            data_as_list = zip(res['phase'][near_adj_matr[j]].T,np.array([norm_coords]*num_iters), [theta_r]*num_iters, [params]*num_iters)\n",
    "            arg3 = [(x[2]) for x in data_as_list]\n",
    "\n",
    "            data_as_list = zip(res['phase'][near_adj_matr[j]].T,np.array([norm_coords]*num_iters), [theta_r]*num_iters, [params]*num_iters)\n",
    "            arg4 = [(x[3]) for x in data_as_list]\n",
    "\n",
    "            futures = client.map(f, arg1, arg2, arg3, arg4)\n",
    "            progress(futures)\n",
    "            res_as_list = client.gather(futures)\n",
    "    \n",
    "            local_angle[j]=np.stack([x[0] for x in res_as_list], axis=0).astype('float32') \n",
    "            local_sf[j]=np.stack([x[1] for x in res_as_list], axis=0).astype('float32') \n",
    "            local_rs[j]=np.stack([x[2] for x in res_as_list], axis=0).astype('float32')\n",
    "            local_off[j]=np.stack([x[3] for x in res_as_list], axis=0).astype('float32')  \n",
    "    \n",
    "    res['direction'] = local_angle \n",
    "    res['spatial_freuency']= local_sf\n",
    "    res['rs']= local_rs\n",
    "    res['offs']= local_off\n",
    "    if cluster not in res_global:\n",
    "        res_global[cluster]={}\n",
    "    res_global[cluster][task_phase]=res\n",
    "    i+=1\n",
    "    \n",
    "with open('/home1/anup.das/dense-session-share_081224/Results/res_global_gamma_39491886.pkl', 'wb') as f:\n",
    "        pickle.dump(res_global, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803963fb-2414-4d1d-9793-f282bfa3518e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_env",
   "language": "python",
   "name": "py3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
